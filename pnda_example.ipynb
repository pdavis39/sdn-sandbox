{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import json\n",
    "import avro.schema\n",
    "import avro.io\n",
    "import io\n",
    "import datetime\n",
    "import uuid\n",
    "import time\n",
    "import sys\n",
    "from io import BytesIO     # for handling byte strings\n",
    "from io import StringIO    # for handling unicode strings\n",
    "import avro\n",
    "from random import randint\n",
    "#from avro.datafile import DataFileWriter\n",
    "from avro.io import DatumWriter\n",
    "from argparse import RawTextHelpFormatter\n",
    "\n",
    "#https://github.com/pndaproject/example-applications/blob/develop/jupyter-notebooks/notebooks/Example%20Platform-library%20PySpark%20Notebook.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'basestring' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-96fc61d91a77>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'in_bytes'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'out_bytes'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'in_pks'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'out_pks'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;31m#generate example datasets (update year, month, day, and hour as you wish)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m \u001b[0mgenerate_sample_datasets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost_ips\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2016\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m26\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-96fc61d91a77>\u001b[0m in \u001b[0;36mgenerate_sample_datasets\u001b[0;34m(host_ips, metric_ids, year, month, day, hour)\u001b[0m\n\u001b[1;32m      9\u001b[0m                 \u001b[0;34m{\u001b[0m\u001b[0;34m\"name\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"rawdata\"\u001b[0m\u001b[0;34m,\u001b[0m   \u001b[0;34m\"type\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"bytes\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             ]}'''\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mschema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mavro_schema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mbytes_writer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBinaryEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_writer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/my-projects-env/lib/python3.7/site-packages/avro/schema.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(json_string)\u001b[0m\n\u001b[1;32m    992\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m   \u001b[0;31m# construct the Avro Schema object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 994\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mmake_avsc_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.virtualenvs/my-projects-env/lib/python3.7/site-packages/avro/schema.py\u001b[0m in \u001b[0;36mmake_avsc_object\u001b[0;34m(json_data, names)\u001b[0m\n\u001b[1;32m    942\u001b[0m         \u001b[0mfields\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fields'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    943\u001b[0m         \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'doc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 944\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mRecordSchema\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfields\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother_props\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    945\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mSchemaParseException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unknown Named Type: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/my-projects-env/lib/python3.7/site-packages/avro/schema.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, namespace, fields, names, schema_type, doc, other_props)\u001b[0m\n\u001b[1;32m    739\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m       NamedSchema.__init__(self, schema_type, name, namespace, names,\n\u001b[0;32m--> 741\u001b[0;31m                            other_props)\n\u001b[0m\u001b[1;32m    742\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mschema_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'record'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/my-projects-env/lib/python3.7/site-packages/avro/schema.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, type, name, namespace, names, other_props)\u001b[0m\n\u001b[1;32m    291\u001b[0m       \u001b[0mfail_msg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Named Schemas must have a non-empty name.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mSchemaParseException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfail_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m     \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m       \u001b[0mfail_msg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'The name property must be a string.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mSchemaParseException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfail_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'basestring' is not defined"
     ]
    }
   ],
   "source": [
    "def generate_sample_datasets (host_ips, metric_ids, year, month, day, hour):\n",
    "    avro_schema = '''\n",
    "           {\"namespace\": \"pnda.entity\",\n",
    "             \"type\": \"record\",\n",
    "             \"name\": \"event\",\n",
    "             \"fields\": [\n",
    "                {\"name\": \"timestamp\", \"type\": \"long\"},\n",
    "                {\"name\": \"source\",    \"type\": \"string\"},\n",
    "                {\"name\": \"rawdata\",   \"type\": \"bytes\"}\n",
    "            ]}'''\n",
    "    schema = avro.schema.parse(avro_schema)\n",
    "    bytes_writer = io.BytesIO()\n",
    "    encoder = avro.io.BinaryEncoder(bytes_writer)\n",
    "    #create hdfs folder structure\n",
    "    dir = create_hdfs_dirs (year, month, day, hour)\n",
    "    filename = str(uuid.uuid4()) + '.avro'\n",
    "    filepath = dir + filename\n",
    "    tmp_file = '/tmp/' + filename\n",
    "    writer = DataFileWriter(open(tmp_file, \"w\"), DatumWriter(), schema)\n",
    "    start_dt = datetime.datetime(year, month, day, hour, 0, 0) \n",
    "    start_ts = int(time.mktime(start_dt.timetuple()))\n",
    "    end_dt = start_dt.replace(hour=hour+1)\n",
    "    end_ts = int(time.mktime(end_dt.timetuple()))\n",
    "\n",
    "    for ts in xrange(start_ts, end_ts, 1):\n",
    "        #generate random pnda record on per host ip basis\n",
    "        for host_ip in host_ips:\n",
    "            record = {}\n",
    "            record['timestamp'] = (ts * 1000)\n",
    "            record['source'] = 'samples'\n",
    "            record['rawdata'] = generate_random_metrics(host_ip, metric_ids)\n",
    "           #encode avro\n",
    "            writer.append(record)\n",
    "    writer.close()\n",
    "    #subprocess.Popen(['hadoop', 'fs', '-copyFromLocal', tmp_file, dir])\n",
    "    return filepath\n",
    "\n",
    "def generate_random_metrics (host_ip, metric_ids):\n",
    "    raw_data = {'host': host_ip}\n",
    "    for id in metric_ids:\n",
    "        raw_data[id] = str(randint(0, 100))\n",
    "    return json.dumps(raw_data).encode('utf-8')\n",
    "\n",
    "def create_hdfs_dirs (year, month, day, hour):\n",
    "    dir = \"datas/source=samples/year=%0d/month=%02d/day=%02d/hour=%02d/\" % (year, month, day, hour)\n",
    "    subprocess.Popen(['hadoop', 'fs', '-mkdir', '-p', dir])\n",
    "    return dir    \n",
    "\n",
    "#example host ips (update as you wish)\n",
    "host_ips = ['10.0.0.1', '10.0.0.2', '10.0.0.3']\n",
    "#example metric list (update as you wish)\n",
    "metrics=['in_bytes', 'out_bytes', 'in_pks', 'out_pks']\n",
    "#generate example datasets (update year, month, day, and hour as you wish)\n",
    "generate_sample_datasets(host_ips, metrics, 2016, 4, 26, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
